{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "413ff4ae-4429-4720-8dc8-f6b8c03734de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import morfeusz2\n",
    "\n",
    "def is_legal_word(morph, slowo):\n",
    "    analiza = morf.analyse(slowo)\n",
    "    if slowo == \"satyn\":\n",
    "        print(analiza)\n",
    "    for interpretacja in analiza:\n",
    "        # print(analiza)\n",
    "        forma_gramatyczna = interpretacja[2][2]\n",
    "        # print(forma_gramatyczna)\n",
    "        if forma_gramatyczna.startswith(\"subst:sg:nom\"):\n",
    "            return True\n",
    "        # if forma_gramatyczna.startswith((\"imps\", \"fin\", \"bedzie\", \"aglt\", \"praet\", \"impt\", \"imps\", \"inf\", \"pcon\", \"pant\", \"ger\", \"pact\", \"ppas\")):\n",
    "        if forma_gramatyczna.startswith(\"inf\"):\n",
    "            return True\n",
    "        if forma_gramatyczna.startswith(\"adj:sg:nom\") and \":f:\" not in forma_gramatyczna and \":n:\" not in forma_gramatyczna:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5a4db0b5-8c1f-4f43-8dc8-951e2f726322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28225\n",
      "[(0, 1, ('satyn', 'satyna', 'subst:pl:gen:f', ['nazwa_pospolita'], []))]\n",
      "4892\n"
     ]
    }
   ],
   "source": [
    "with open('5liter.txt', 'r', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "    # words = [\"opera\", \"słoma\", \"domu\", \"czytać\", \"ładny\"]\n",
    "print(len(words))\n",
    "morf = morfeusz2.Morfeusz()\n",
    "legal_words = []\n",
    "# words = [\"żywna\"]\n",
    "for word in words:\n",
    "    word = word.strip()\n",
    "    if is_legal_word(morf, word):\n",
    "        legal_words.append(word)\n",
    "print(len(legal_words))\n",
    "with open('hasła.txt', 'w', encoding='utf-8') as f2:\n",
    "    for word in legal_words:\n",
    "        f2.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e65ed94-730e-43b2-b17d-f0ea3102159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [dict() for _ in range(5)]\n",
    "letter_frequency = dict()\n",
    "with open('hasła.txt', 'r', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        for i, letter in enumerate(word):\n",
    "            if letter not in positions[i]:\n",
    "                positions[i][letter] = 0\n",
    "            positions[i][letter] += 1\n",
    "        for letter in set(word):\n",
    "            if letter not in letter_frequency:\n",
    "                letter_frequency[letter] = 0\n",
    "            letter_frequency[letter] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "266b1d6b-63f6-4eb0-8b3d-400f4ffa22a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 1454, 'a': 2684, 'b': 642, 'u': 881, 'g': 473, 'c': 596, 't': 974, 'r': 1386, 'o': 1527, 's': 1097, 'y': 760, 'd': 671, 'i': 1224, 'n': 1012, 'ć': 489, 'h': 238, 'p': 814, 'e': 1183, 'm': 670, 'f': 241, 'z': 719, 'w': 682, 'j': 335, 'l': 946, 'ż': 210, 'ł': 415, 'ś': 129, 'ń': 52, 'ó': 166, 'ź': 34, 'ą': 145, 'ę': 136, 'v': 1, 'x': 4}\n"
     ]
    }
   ],
   "source": [
    "print(letter_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3604d3bd-91ad-4bd0-8683-9cf3fd79a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('letter_frequencies.json', 'w') as file:\n",
    "#     json.dump(letter_frequency, file)\n",
    "\n",
    "# with open('positions.json', 'w') as file:\n",
    "#     json.dump(positions, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f1324ce-4d17-4f36-9152-a07aa6bc150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.55,\n",
       " 'o': 0.31,\n",
       " 'k': 0.3,\n",
       " 'r': 0.28,\n",
       " 'i': 0.25,\n",
       " 'e': 0.24,\n",
       " 's': 0.22,\n",
       " 'n': 0.21,\n",
       " 't': 0.2,\n",
       " 'l': 0.19,\n",
       " 'u': 0.18,\n",
       " 'p': 0.17,\n",
       " 'y': 0.16,\n",
       " 'z': 0.15,\n",
       " 'w': 0.14,\n",
       " 'd': 0.14,\n",
       " 'm': 0.14,\n",
       " 'b': 0.13,\n",
       " 'c': 0.12,\n",
       " 'ć': 0.1,\n",
       " 'g': 0.1,\n",
       " 'ł': 0.08,\n",
       " 'j': 0.07,\n",
       " 'f': 0.05,\n",
       " 'h': 0.05,\n",
       " 'ż': 0.04,\n",
       " 'ó': 0.03,\n",
       " 'ą': 0.03,\n",
       " 'ę': 0.03,\n",
       " 'ś': 0.03,\n",
       " 'ń': 0.01,\n",
       " 'ź': 0.01,\n",
       " 'x': 0.0,\n",
       " 'v': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict = {k: round(letter_frequency[k]/len(legal_words), 2) for k in sorted(letter_frequency, key=letter_frequency.get, reverse=True)}\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad4a5237-a21f-4e8d-9ee3-6365ae5da3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chances = []\n",
    "for i in range(5):\n",
    "    d = positions[i]\n",
    "    sorted_dict = {k: round(d[k]/len(legal_words), 2) for k in sorted(d, key=d.get, reverse=True)}\n",
    "    chances.append(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f10329af-0ca3-4992-9459-f2e4aaa8eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def green_score(word, chances):\n",
    "    score = 0\n",
    "    if len(set(word)) <5:\n",
    "        return 0\n",
    "    for i, l in enumerate(word):\n",
    "        score += chances[i].get(l, 0)\n",
    "    return score\n",
    "\n",
    "def yellow_score(word, chances, duplicates=False):\n",
    "    score = 0\n",
    "    if not duplicates and len(set(word)) <5:\n",
    "        return 0\n",
    "    for i, l in enumerate(word):\n",
    "        score += chances.get(l, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f73800be-3c44-4b58-aa35-545935286ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opera 0.39\n",
      "koral 0.49\n",
      "setni 0.32999999999999996\n",
      "polka 0.63\n",
      "flora 0.38\n",
      "sroka 0.54\n",
      "okrai 0.3400000000000001\n",
      "torba 0.54\n",
      "opera 17\n",
      "koral 14\n",
      "setni 10\n",
      "polka 17\n",
      "flora 14\n",
      "sroka 21\n",
      "okrai 14\n",
      "torba 16\n"
     ]
    }
   ],
   "source": [
    "words = [\"opera\", \"koral\", \"setni\", \"polka\", \"flora\", \"sroka\", \"okrai\", \"torba\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, green_score(word, chances))\n",
    "for word in words:\n",
    "    print(word, yellow_score(word, letter_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc34095a-4d4c-4fe4-b4d0-fe4a305cd4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soria 0.67\n"
     ]
    }
   ],
   "source": [
    "with open('5liter.txt', 'r', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "    best_score = 0\n",
    "    best_word = \"\"\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        score = green_score(word, chances)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_word = word\n",
    "    print(best_word, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7f8a3ee-163f-43a9-9bbf-657a8d47472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okrai 1.69\n"
     ]
    }
   ],
   "source": [
    "sorted_dict = {k: round(letter_frequency[k]/len(legal_words), 2) for k in sorted(letter_frequency, key=letter_frequency.get, reverse=True)}\n",
    "\n",
    "with open('5liter.txt', 'r', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "    best_score = 0\n",
    "    best_word = \"\"\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        score = yellow_score(word, sorted_dict)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_word = word\n",
    "    print(best_word, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c1c4a1a-be02-4bfd-a1e8-26f1c74a86fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4eef7ddb-bec1-4b05-bcd7-c9dc8c382da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['słoma', 'słota', 'smoła', 'spona', 'stopa', 'szopa', 'szosa']\n",
      "{'s': 1.0, 'a': 1.0, 'o': 1.0, 'ł': 0.43, 'p': 0.43, 'm': 0.29, 't': 0.29, 'z': 0.29, 'n': 0.14}\n"
     ]
    }
   ],
   "source": [
    "with open('hasła.txt', 'r', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "    available_letters = \"abcdefghijklmnoprstuvwxyzóąćęłńśźż\"\n",
    "    available_letters = \"abcdefghjklmnopstuvwxyzóąćęłńśźż\"\n",
    "    available_letters = \"abcdeghijmnopstuvxyzóąćęłńśźż\"\n",
    "    available_words = list(legal_words(words, available_letters, \"s o a\", \"     \"))\n",
    "    # print(len(list(available_words)))\n",
    "    print(len(available_words), available_words)\n",
    "    # d, words_count = get_letter_frequencies(words, available_letters)\n",
    "    # print(words_count)\n",
    "    # d = sorted_dict = {k: round(d[k]/words_count, 2) for k in sorted(d, key=d.get, reverse=True)}\n",
    "    # print(d)\n",
    "    letter_frequency, words_count = get_letter_frequencies(available_words)\n",
    "    sorted_letters = {k: round(letter_frequency[k]/words_count, 2) for k in sorted(letter_frequency, key=letter_frequency.get, reverse=True)}\n",
    "    print(sorted_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5cdc188-e626-4bba-820a-c602eaadd27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnoprstuvwxyzóąćęłńśźż\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(sorted(sorted_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66f2302d-6d8c-41c7-9a86-026cc09560a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "słoma 3.7199999999999998\n",
      "słota 3.7199999999999998\n",
      "smoła 3.72\n",
      "spona 3.57\n",
      "stopa 3.72\n",
      "szopa 3.72\n",
      "szosa 0\n"
     ]
    }
   ],
   "source": [
    "for word in available_words:\n",
    "    print(word, yellow_score(word, sorted_letters, duplicates=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce46da22-f303-47f0-92b5-426b953aaa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ampuł 1.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sorted_unknown_letters = {k:sorted_letters[k] for k in sorted_letters if sorted_letters[k] < 1}\n",
    "\n",
    "with open('5liter.txt', 'r', encoding='utf-8') as file:\n",
    "    words = file.readlines()\n",
    "    best_score = 0\n",
    "    best_word = \"\"\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        score = yellow_score(word, sorted_unknown_letters)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_word = word\n",
    "    print(best_word, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d3a06d58-9f5e-4e6b-ba30-563f41cb7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_words(words, available_letters, green_letters, yellows):\n",
    "    for word in words:\n",
    "        legal_word = True\n",
    "        word = word.strip()\n",
    "        letters = set(word)\n",
    "        for letter in letters:\n",
    "            if letter not in available_letters:\n",
    "                legal_word = False\n",
    "        for w, g in zip(word, green_letters):\n",
    "            if not(g == \" \" or g == w):\n",
    "                legal_word = False\n",
    "        for yellow_letters in yellows:\n",
    "            for w, y in zip(word, yellow_letters):\n",
    "                if not \" \" == y:\n",
    "                    if w == y:\n",
    "                        legal_word = False\n",
    "                    if not y in letters:\n",
    "                        legal_word = False\n",
    "        if legal_word:\n",
    "            yield word\n",
    "\n",
    "def get_letter_frequencies(words):\n",
    "    letter_frequency = dict()\n",
    "    words_count = len(words)\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        letters = set(word)\n",
    "        for letter in letters:\n",
    "            if letter not in letter_frequency:\n",
    "                letter_frequency[letter] = 0\n",
    "            letter_frequency[letter] += 1\n",
    "    return letter_frequency, words_count\n",
    "\n",
    "def next_prediction(available_letters, green, yellow):\n",
    "    with open('hasła.txt', 'r', encoding='utf-8') as file:\n",
    "        words = file.readlines()\n",
    "        available_words = list(legal_words(words, available_letters, green, yellow))\n",
    "        print(len(available_words))\n",
    "        letter_frequency, words_count = get_letter_frequencies(available_words)\n",
    "        sorted_letters = {k: round(letter_frequency[k]/words_count, 2) for k in sorted(letter_frequency, key=letter_frequency.get, reverse=True)}\n",
    "        sorted_unknown_letters = {k:sorted_letters[k] for k in sorted_letters if sorted_letters[k] < 1}\n",
    "\n",
    "    positions = [dict() for _ in range(5)]\n",
    "    letter_frequency = dict()\n",
    "    for word in available_words:\n",
    "        word = word.strip()\n",
    "        for i, letter in enumerate(word):\n",
    "            if letter not in positions[i]:\n",
    "                positions[i][letter] = 0\n",
    "            positions[i][letter] += 1\n",
    "        for letter in set(word):\n",
    "            if letter not in letter_frequency:\n",
    "                letter_frequency[letter] = 0\n",
    "            letter_frequency[letter] += 1\n",
    "    \n",
    "    with open('5liter.txt', 'r', encoding='utf-8') as file:\n",
    "        words = file.readlines()\n",
    "        best_elimination_score = 0\n",
    "        best_elimination_word = \"\"\n",
    "        best_balanced_word = \"\"\n",
    "        best_balanced_score = 0\n",
    "        for word in words:\n",
    "            word = word.strip()\n",
    "            score = yellow_score(word, sorted_unknown_letters)\n",
    "            if score > best_elimination_score:\n",
    "                best_elimination_score = score\n",
    "                best_elimination_word = word\n",
    "            balanced_score = (score + green_score(word, positions)) / 2\n",
    "            if balanced_score > best_balanced_score:\n",
    "                best_balanced_score = balanced_score\n",
    "                best_balanced_word = word\n",
    "    best_score = 0\n",
    "    best_word = \"\"\n",
    "    for word in available_words:\n",
    "        word = word.strip()\n",
    "        score = yellow_score(word, sorted_letters, duplicates=False)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_word = word\n",
    "    return {\"best_elimination\":best_elimination_word, \"best_guess\":best_word, \"best_balanced\":best_balanced_word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16cf47c6-eaa8-42d0-9cf0-4ec5f74031b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_elimination': 'okrai', 'best_guess': 'orska', 'best_balanced': 'soria'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = \"abcdefghijklmnoprstuvwxyzóąćęłńśźż\"\n",
    "green = \"     \"\n",
    "yellow = [\"     \"]\n",
    "available_letters = \"abcdefghijklmnoprstuvwxyzóąćęłńśźż\"\n",
    "\n",
    "next_prediction(available_letters, green, yellow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
